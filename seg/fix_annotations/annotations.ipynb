{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca645813-c642-4950-9063-a177e14b23be",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: C:\\Users\\lampu\\miniconda3\\envs\\annotations\n",
      "\n",
      "  added / updated specs:\n",
      "    - pandas\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    certifi-2022.9.24          |  py310haa95532_0         155 KB\n",
      "    pandas-1.4.4               |  py310hd77b12b_0         8.7 MB\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:         8.8 MB\n",
      "\n",
      "The following packages will be UPDATED:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 4.13.0\n",
      "  latest version: 22.9.0\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  ca-certificates                      2022.4.26-haa95532_0 --> 2022.07.19-haa95532_0\n",
      "  certifi                       2022.5.18.1-py310haa95532_0 --> 2022.9.24-py310haa95532_0\n",
      "  openssl                                 1.1.1o-h2bbff1b_0 --> 1.1.1q-h2bbff1b_0\n",
      "  pandas                              1.4.2-py310hd77b12b_0 --> 1.4.4-py310hd77b12b_0\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "\n",
      "certifi-2022.9.24    | 155 KB    |            |   0% \n",
      "certifi-2022.9.24    | 155 KB    | ########## | 100% \n",
      "certifi-2022.9.24    | 155 KB    | ########## | 100% \n",
      "\n",
      "pandas-1.4.4         | 8.7 MB    |            |   0% \n",
      "pandas-1.4.4         | 8.7 MB    | 4          |   5% \n",
      "pandas-1.4.4         | 8.7 MB    | #6         |  17% \n",
      "pandas-1.4.4         | 8.7 MB    | ##9        |  30% \n",
      "pandas-1.4.4         | 8.7 MB    | ####2      |  43% \n",
      "pandas-1.4.4         | 8.7 MB    | #####7     |  57% \n",
      "pandas-1.4.4         | 8.7 MB    | ######9    |  69% \n",
      "pandas-1.4.4         | 8.7 MB    | ########2  |  83% \n",
      "pandas-1.4.4         | 8.7 MB    | #########8 |  98% \n",
      "pandas-1.4.4         | 8.7 MB    | ########## | 100% \n",
      "Preparing transaction: ...working... done\n",
      "Verifying transaction: ...working... done\n",
      "Executing transaction: ...working... done\n",
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: C:\\Users\\lampu\\miniconda3\\envs\\annotations\n",
      "\n",
      "  added / updated specs:\n",
      "    - networkx\n",
      "\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  networkx           pkgs/main/noarch::networkx-2.7.1-pyhd~ --> pkgs/main/win-64::networkx-2.8.4-py310haa95532_0\n",
      "\n",
      "\n",
      "Preparing transaction: ...working... done\n",
      "Verifying transaction: ...working... done\n",
      "Executing transaction: ...working... done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 4.13.0\n",
      "  latest version: 22.9.0\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 4.13.0\n",
      "  latest version: 22.9.0\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!conda install --yes --prefix {sys.prefix} pandas\n",
    "!conda install --yes --prefix {sys.prefix} networkx\n",
    "!conda install --yes --prefix {sys.prefix} matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08bc5602-b28f-46ad-82f0-ab422e61669f",
   "metadata": {},
   "source": [
    "# 1) Import JSON into DataFrame\n",
    "\n",
    "Export annotations from CVAT as COCO JSON. \n",
    "\n",
    "Put the json file in the working directory and change the variable \"filename\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "317dede2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# utilities\n",
    "\n",
    "def findCategory(data):\n",
    "    # find categories\n",
    "    cats = data[\"categories\"]\n",
    "    category = pd.DataFrame(cats)\n",
    "    category = category.drop(['supercategory'], axis=1)\n",
    "    category = category.rename(columns={'id': 'category_id'})\n",
    "    return category\n",
    "\n",
    "def findImages(data):\n",
    "    img = data[\"images\"]\n",
    "    images = pd.DataFrame(img)\n",
    "    \n",
    "    # unwanted columns exist if exported from CVAT. Not if generated by my code\n",
    "    if set(['license','flickr_url','coco_url','date_captured']).issubset(images.columns):\n",
    "        images = images.drop(columns=['license','flickr_url','coco_url','date_captured'])\n",
    "    \n",
    "    return images\n",
    "\n",
    "def findAnnotations(data):\n",
    "    anno = data[\"annotations\"]\n",
    "    df = pd.DataFrame(anno)\n",
    "    return df\n",
    "\n",
    "# convert all np.integer, np.floating and np.ndarray into json recognisable int, float and lists\n",
    "class NpEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.integer):\n",
    "            return int(obj)\n",
    "        if isinstance(obj, np.floating):\n",
    "            return float(obj)\n",
    "        if isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        return json.JSONEncoder.default(self, obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a51d1d6-811f-4b2e-8e2e-ef4a736c85e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import json\n",
    "\n",
    "df = pd.DataFrame()\n",
    "# area = 'A14 Tothill'\n",
    "filename = './input/combined.json'\n",
    "with open(filename, 'r') as file:\n",
    "    data = json.load(file)\n",
    "    \n",
    "    category = findCategory(data)\n",
    "\n",
    "    images = findImages(data)\n",
    "    nos_image = images['id'].max()\n",
    "\n",
    "    df = findAnnotations(data)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dc7d845b",
   "metadata": {},
   "source": [
    "In case the old CVAT xml is pursued..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce358d52-4850-488e-bf91-54e40e557acc",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lampu\\AppData\\Local\\Temp\\ipykernel_20512\\2225267564.py:17: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(dict_train, ignore_index = True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>image_id</th>\n",
       "      <th>category_id</th>\n",
       "      <th>segmentation</th>\n",
       "      <th>area</th>\n",
       "      <th>bbox</th>\n",
       "      <th>iscrowd</th>\n",
       "      <th>attributes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>[[663.0, 9.31, 732.46, 957.05, 771.05, 963.22,...</td>\n",
       "      <td>31932.0</td>\n",
       "      <td>[663.0, 9.31, 108.05, 953.91]</td>\n",
       "      <td>0</td>\n",
       "      <td>{'occluded': False}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>[[669.18, 13.94, 761.79, 907.66, 789.57, 904.5...</td>\n",
       "      <td>22183.0</td>\n",
       "      <td>[669.18, 13.94, 120.39, 893.72]</td>\n",
       "      <td>0</td>\n",
       "      <td>{'occluded': False}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>[[679.98, 13.94, 797.29, 1018.79, 831.25, 1021...</td>\n",
       "      <td>29303.0</td>\n",
       "      <td>[679.98, 13.94, 151.27, 1007.94]</td>\n",
       "      <td>0</td>\n",
       "      <td>{'occluded': False}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>[[690.79, 7.77, 820.45, 987.92, 863.66, 995.64...</td>\n",
       "      <td>33488.0</td>\n",
       "      <td>[690.79, 7.77, 172.87, 987.87]</td>\n",
       "      <td>0</td>\n",
       "      <td>{'occluded': False}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>[[693.87, 13.94, 845.14, 901.48, 877.56, 896.8...</td>\n",
       "      <td>27143.0</td>\n",
       "      <td>[693.87, 12.4, 183.69, 889.08]</td>\n",
       "      <td>0</td>\n",
       "      <td>{'occluded': False}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1812</th>\n",
       "      <td>1813</td>\n",
       "      <td>2328</td>\n",
       "      <td>4</td>\n",
       "      <td>[[718.57, 6.23, 754.07, 47.9, 794.2, 89.58, 82...</td>\n",
       "      <td>18234.0</td>\n",
       "      <td>[718.57, 3.14, 327.23, 395.15]</td>\n",
       "      <td>0</td>\n",
       "      <td>{'occluded': False}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1813</th>\n",
       "      <td>1814</td>\n",
       "      <td>2328</td>\n",
       "      <td>11</td>\n",
       "      <td>[[84.11, 185.55, 145.96, 184.31, 174.42, 145.9...</td>\n",
       "      <td>2652.0</td>\n",
       "      <td>[84.11, 139.78, 90.31, 45.77]</td>\n",
       "      <td>0</td>\n",
       "      <td>{'occluded': False}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1814</th>\n",
       "      <td>1815</td>\n",
       "      <td>2328</td>\n",
       "      <td>11</td>\n",
       "      <td>[[1044.07, 132.36, 1056.44, 170.71, 1131.9, 16...</td>\n",
       "      <td>3279.0</td>\n",
       "      <td>[1044.07, 118.75, 87.83, 51.96]</td>\n",
       "      <td>0</td>\n",
       "      <td>{'occluded': False}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1815</th>\n",
       "      <td>1816</td>\n",
       "      <td>2329</td>\n",
       "      <td>4</td>\n",
       "      <td>[[806.55, 38.64, 854.4, 34.01, 880.64, 64.88, ...</td>\n",
       "      <td>7664.0</td>\n",
       "      <td>[806.55, 34.01, 422.93, 290.19]</td>\n",
       "      <td>0</td>\n",
       "      <td>{'occluded': False}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1816</th>\n",
       "      <td>1817</td>\n",
       "      <td>2333</td>\n",
       "      <td>11</td>\n",
       "      <td>[[0.0, 425.2, 319.15, 403.27, 682.85, 415.64, ...</td>\n",
       "      <td>160258.0</td>\n",
       "      <td>[0.0, 341.42, 2464.0, 98.97]</td>\n",
       "      <td>0</td>\n",
       "      <td>{'occluded': False}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1817 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id image_id category_id  \\\n",
       "0        1        5           4   \n",
       "1        2        6           4   \n",
       "2        3        7           4   \n",
       "3        4        8           4   \n",
       "4        5        9           4   \n",
       "...    ...      ...         ...   \n",
       "1812  1813     2328           4   \n",
       "1813  1814     2328          11   \n",
       "1814  1815     2328          11   \n",
       "1815  1816     2329           4   \n",
       "1816  1817     2333          11   \n",
       "\n",
       "                                           segmentation      area  \\\n",
       "0     [[663.0, 9.31, 732.46, 957.05, 771.05, 963.22,...   31932.0   \n",
       "1     [[669.18, 13.94, 761.79, 907.66, 789.57, 904.5...   22183.0   \n",
       "2     [[679.98, 13.94, 797.29, 1018.79, 831.25, 1021...   29303.0   \n",
       "3     [[690.79, 7.77, 820.45, 987.92, 863.66, 995.64...   33488.0   \n",
       "4     [[693.87, 13.94, 845.14, 901.48, 877.56, 896.8...   27143.0   \n",
       "...                                                 ...       ...   \n",
       "1812  [[718.57, 6.23, 754.07, 47.9, 794.2, 89.58, 82...   18234.0   \n",
       "1813  [[84.11, 185.55, 145.96, 184.31, 174.42, 145.9...    2652.0   \n",
       "1814  [[1044.07, 132.36, 1056.44, 170.71, 1131.9, 16...    3279.0   \n",
       "1815  [[806.55, 38.64, 854.4, 34.01, 880.64, 64.88, ...    7664.0   \n",
       "1816  [[0.0, 425.2, 319.15, 403.27, 682.85, 415.64, ...  160258.0   \n",
       "\n",
       "                                  bbox iscrowd           attributes  \n",
       "0        [663.0, 9.31, 108.05, 953.91]       0  {'occluded': False}  \n",
       "1      [669.18, 13.94, 120.39, 893.72]       0  {'occluded': False}  \n",
       "2     [679.98, 13.94, 151.27, 1007.94]       0  {'occluded': False}  \n",
       "3       [690.79, 7.77, 172.87, 987.87]       0  {'occluded': False}  \n",
       "4       [693.87, 12.4, 183.69, 889.08]       0  {'occluded': False}  \n",
       "...                                ...     ...                  ...  \n",
       "1812    [718.57, 3.14, 327.23, 395.15]       0  {'occluded': False}  \n",
       "1813     [84.11, 139.78, 90.31, 45.77]       0  {'occluded': False}  \n",
       "1814   [1044.07, 118.75, 87.83, 51.96]       0  {'occluded': False}  \n",
       "1815   [806.55, 34.01, 422.93, 290.19]       0  {'occluded': False}  \n",
       "1816      [0.0, 341.42, 2464.0, 98.97]       0  {'occluded': False}  \n",
       "\n",
       "[1817 rows x 8 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import re\n",
    "import json\n",
    "\n",
    "df = pd.DataFrame()\n",
    "area = 'A14 Tothill'\n",
    "filename = 'train_221222.csv'\n",
    "# filename = 'new_'+ area +'.csv'\n",
    "with open(filename, 'r', encoding='utf-8-sig', errors=\"surrogateescape\") as file:\n",
    "    for i, line in enumerate(file,1):\n",
    "        dict_train = eval(line)\n",
    "        add = pd.DataFrame.from_dict(dict_train, orient='index')\n",
    "        add = add.transpose()\n",
    "        if i == 1:\n",
    "            df = df.append(dict_train, ignore_index = True)\n",
    "        else:\n",
    "            df = pd.concat([df, add], ignore_index = True)\n",
    "\n",
    "        # df = df.append(dict_train, ignore_index = True)\n",
    "\n",
    "# # converting json dataset from dictionary to dataframe\n",
    "# train = pd.DataFrame.from_dict(dict_train, orient='index')\n",
    "# train.reset_index(level=0, inplace=True)\n",
    "\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f948fc47",
   "metadata": {},
   "source": [
    "## 2a) Query numbers and images of a certain category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9adbf90d-ae78-4c4b-8ca6-1712fb999a2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_x</th>\n",
       "      <th>image_id</th>\n",
       "      <th>category_id</th>\n",
       "      <th>segmentation</th>\n",
       "      <th>area</th>\n",
       "      <th>bbox</th>\n",
       "      <th>file_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>293</td>\n",
       "      <td>1635</td>\n",
       "      <td>10</td>\n",
       "      <td>[[1620.8, 529.2, 1616.9, 532.9, 1601.6, 532.9,...</td>\n",
       "      <td>19439.0</td>\n",
       "      <td>[1574.7, 529.2, 180.9, 124.6]</td>\n",
       "      <td>A12Area6SwallowsCrossMountnessingHuttonBrentwo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id_x  image_id  category_id  \\\n",
       "0   293      1635           10   \n",
       "\n",
       "                                        segmentation     area  \\\n",
       "0  [[1620.8, 529.2, 1616.9, 532.9, 1601.6, 532.9,...  19439.0   \n",
       "\n",
       "                            bbox  \\\n",
       "0  [1574.7, 529.2, 180.9, 124.6]   \n",
       "\n",
       "                                           file_name  \n",
       "0  A12Area6SwallowsCrossMountnessingHuttonBrentwo...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Query category_id\n",
    "defect = 'potholes'\n",
    "\n",
    "# match the defect with the category df\n",
    "# the extraction outputs a series. use [0] to get the value\n",
    "q_catid = category[category['name']==defect]['category_id'].values[0]\n",
    "\n",
    "# Excerpt df\n",
    "ans = df[df['category_id']==q_catid]\n",
    "# add file_name\n",
    "ans = ans.merge(images[['id','file_name']], left_on='image_id', right_on='id')\n",
    "ans = ans.drop(columns=['iscrowd','attributes','id_y'])\n",
    "\n",
    "# Export CSV of images the defect\n",
    "csv_need = False\n",
    "if csv_need == True:\n",
    "    name = defect+'_image.csv'\n",
    "    ans.to_csv(name)\n",
    "\n",
    "\n",
    "ans"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9ff3f4e0",
   "metadata": {},
   "source": [
    "## 2b) Move files included in JSON\n",
    "\n",
    "Useful in cases like after spliting a training and testing set with cocosplit, input the testing set and copy the images into another directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "81a44ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob, shutil, os\n",
    "\n",
    "IMAGE_DIR = '../data/train/images/'\n",
    "# IMAGE_DIR = 'D:\\\\04 Trained/230110/images/train/'\n",
    "DST_DIR = './output_img/'\n",
    "\n",
    "# filter the images with defects in \"annotations\"\n",
    "ans = df\n",
    "ans = ans.merge(images[['id','file_name']], left_on='image_id', right_on='id')\n",
    "ans = ans.drop(columns=['iscrowd','attributes','id_y'])\n",
    "concerned_img = ans['file_name'].unique().tolist()\n",
    "\n",
    "# copy the concerned images\n",
    "for i in range(len(concerned_img)):\n",
    "    IMAGE_PATHS = glob.glob(os.path.join(IMAGE_DIR, concerned_img[i]))\n",
    "    try:\n",
    "        shutil.copy(IMAGE_PATHS[0],DST_DIR)\n",
    "    except:\n",
    "        print(concerned_img[i],' not found.')\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "487ffaf7-5186-4f98-ae40-7e9ce848b4ad",
   "metadata": {},
   "source": [
    "# 2) Count numbers of defects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6130a5e1-5032-497f-bf2b-3ab0230f4f1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "641 out of 641 images have defects.\n",
      "1451 defects in total\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category_id</th>\n",
       "      <th>counts</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>177</td>\n",
       "      <td>raveling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>290</td>\n",
       "      <td>crack_transverse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>286</td>\n",
       "      <td>crack_longitudinal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>94</td>\n",
       "      <td>crack_edge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>45</td>\n",
       "      <td>potholes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>11</td>\n",
       "      <td>270</td>\n",
       "      <td>patch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>12</td>\n",
       "      <td>289</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   category_id  counts                name\n",
       "0            2     177            raveling\n",
       "1            3     290    crack_transverse\n",
       "2            4     286  crack_longitudinal\n",
       "3            5      94          crack_edge\n",
       "4           10      45            potholes\n",
       "5           11     270               patch\n",
       "6           12     289             unknown"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count total number of images\n",
    "findTotal = False\n",
    "if findTotal == True:\n",
    "    if area == 'A14 Tothill':\n",
    "        nos_image = 2343\n",
    "    elif area == 'A12 Mountnessing':\n",
    "        nos_image = 6580\n",
    "# if not imported from json, manually input nos. images\n",
    "# nos_image = [self defined]\n",
    "        \n",
    "# Count images with defects by querying image id\n",
    "qall = True\n",
    "if qall == True:\n",
    "    start_id = 1\n",
    "    end_id = max(df['image_id'])\n",
    "elif qall == False:\n",
    "    start_id = 4356\n",
    "    end_id = 6580\n",
    "\n",
    "df2 = df[(df['image_id']>=start_id) & (df['image_id']<=end_id)]\n",
    "\n",
    "nos_image_d = df2['image_id'].nunique()\n",
    "\n",
    "nos_defects = len(df2['id'])\n",
    "\n",
    "print(f'{nos_image_d} out of {nos_image} images have defects.\\n{nos_defects} defects in total')\n",
    "\n",
    "defect_cat = pd.pivot_table(df2, values='id', index='category_id', aggfunc='count')\n",
    "\n",
    "defect_cat = defect_cat.merge(category[['category_id','name']], left_on='category_id', right_on='category_id')\n",
    "defect_cat = defect_cat.rename(columns={'id': 'counts'})\n",
    "defect_cat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb375ecd-bab2-47a1-a000-a5f5f500ad14",
   "metadata": {},
   "source": [
    "# 3) Create YOLO Label Files from COCO JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0be6f26e-002d-476d-aca6-73f240021e01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels of 5882 images prepared!\n",
      "custom.yaml prepared!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import yaml\n",
    "\n",
    "# For training without specific categories\n",
    "cat_elim = [4, 11]\n",
    "\n",
    "# find if image_id has any defects\n",
    "for i in images['id']:\n",
    "    if (i in df['image_id'].unique()) == True:\n",
    "        # print(f'image {i} has defect')\n",
    "        \n",
    "        # Concatenate df and images for the text file\n",
    "        df2 = df[df['image_id']==i]\n",
    "        image2 = images.loc[(images['id']==i),['id','width','height','file_name']]\n",
    "        image2 = image2.rename(columns={'id': 'image_id'})\n",
    "        df2 = df2.drop(columns=['area','bbox','iscrowd','attributes'])\n",
    "        df2 = df2.merge(image2,left_on='image_id',right_on='image_id') \n",
    "        \n",
    "        # Normalise polygon points\n",
    "        poly_print = []\n",
    "        im_width = df2['width'][0]\n",
    "        im_height = df2['height'][0]\n",
    "        for f, x in enumerate(df2['segmentation'].to_list()):\n",
    "            if df2['category_id'][f] in cat_elim:\n",
    "                # skip unwanted categories\n",
    "                continue\n",
    "            else:\n",
    "                poly = [df2['category_id'][f]-1]\n",
    "                # print(f'image {i} polygon length {len(x[0])}')\n",
    "                for y in range(1,len(x[0]),2):\n",
    "                    # print(x,y)\n",
    "                    ptx = x[0][y-1]/im_width\n",
    "                    pty = x[0][y]/im_height\n",
    "                    poly.extend([ptx, pty])\n",
    "                # poly.extend([poly[1],poly[2]])                      # YOLO does not need polygon points to form a close loop\n",
    "                poly_print.append(poly)\n",
    "                poly = []\n",
    "        \n",
    "        fname = re.findall(r'(.*)(?:.jpg)$',df2['file_name'][0])[0]\n",
    "        fname = \"./txt_labels/\"+fname+\".txt\"\n",
    "        with open(fname, \"w\") as outfile:\n",
    "            for num, j in enumerate(poly_print):\n",
    "                outfile.write(' '.join(str(e) for e in j))\n",
    "                # print(f'image {i} defect {num} of {len(poly_print)}')\n",
    "                if num==len(poly_print)-1: outfile.write('')\n",
    "                else: outfile.write('\\n')\n",
    "        poly_print = []\n",
    "    else:\n",
    "        fname = re.findall(r'(.*)(?:.jpg)$',images.loc[(images['id']==i),'file_name'].values[0])[0]\n",
    "        fname = \"./txt_labels/\"+fname+\".txt\"\n",
    "        with open(fname, \"w\") as outfile:\n",
    "            outfile.write('')\n",
    "\n",
    "print(f'Labels of {nos_image} images prepared!')\n",
    "\n",
    "# Create data.yaml file\n",
    "nc = len(category['category_id'])\n",
    "names = category['name'].to_list()\n",
    "with open(r'./custom.yaml', \"w\") as outfile:\n",
    "    outfile.write('train: ./data/train/images \\n')\n",
    "    outfile.write('val: ./data/val/images \\n')\n",
    "    outfile.write('test: ./data/test/images \\n \\n')\n",
    "    outfile.write(f'nc: {nc} \\n')\n",
    "    outfile.write(f'names: {names} \\n')\n",
    "print('custom.yaml prepared!')\n",
    "\n",
    "# np.array(df2['segmentation'].to_list()[0])/10"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5f0a942a-6633-43c6-b273-8738d8f44f5e",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "\n",
    "Now move the folder \"txt_labels\" to the corresponding ./data/[test/train/val] folder\n",
    "\n",
    "Move also a the custom.yaml to ./data\n",
    "\n",
    "Leave the folder \"txt_labels\" in this ./fix_annotation folder for subsequent annotation files.\n",
    "\n",
    "Happy training!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f371cfe3",
   "metadata": {},
   "source": [
    "# 4) Convert YOLO Labels to COCO JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97e3dfb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defect id: 139, image: ['A12Area6SwallowsCrossMountnessingHuttonBrentwoodLondon_sideview_000020_003239_Lane2.jpg']\n",
      "defect id: 148, image: ['A12Area6SwallowsCrossMountnessingHuttonBrentwoodLondon_sideview_000020_003239_Lane2.jpg']\n",
      "defect id: 162, image: ['A12Area6SwallowsCrossMountnessingHuttonBrentwoodLondon_sideview_000020_003242_Lane2.jpg']\n",
      "defect id: 187, image: ['A12Area6SwallowsCrossMountnessingHuttonBrentwoodLondon_sideview_000020_003357_Lane2.jpg']\n",
      "defect id: 226, image: ['A12Area6SwallowsCrossMountnessingHuttonBrentwoodLondon_sideview_000023_000238_Lane1.jpg']\n",
      "defect id: 277, image: ['A12Area6SwallowsCrossMountnessingHuttonBrentwoodLondon_sideview_000023_000345_Lane1.jpg']\n",
      "defect id: 307, image: ['A12Area6SwallowsCrossMountnessingHuttonBrentwoodLondon_sideview_000023_000392_Lane1.jpg']\n",
      "defect id: 387, image: ['A12Area6SwallowsCrossMountnessingHuttonBrentwoodLondon_sideview_000023_000671_Lane1.jpg']\n",
      "defect id: 564, image: ['A12Area6SwallowsCrossMountnessingHuttonBrentwoodLondon_sideview_000023_001012_Lane1.jpg']\n",
      "defect id: 660, image: ['A12Area6SwallowsCrossMountnessingHuttonBrentwoodLondon_sideview_000024_000507_Lane1.jpg']\n",
      "defect id: 720, image: ['A12Area6SwallowsCrossMountnessingHuttonBrentwoodLondon_sideview_000025_001361_Lane2.jpg']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>image_id</th>\n",
       "      <th>category_id</th>\n",
       "      <th>segmentation</th>\n",
       "      <th>area</th>\n",
       "      <th>bbox</th>\n",
       "      <th>iscrowd</th>\n",
       "      <th>attributes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>[[2410.0, 638.8, 2406.3, 642.5, 2406.3, 653.8,...</td>\n",
       "      <td>3226.7</td>\n",
       "      <td>[2402.4, 638.8, 57.7, 64.1]</td>\n",
       "      <td>0</td>\n",
       "      <td>{'occluded': False}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>[[2329.2, 393.1, 2325.3, 396.8, 2302.4, 396.8,...</td>\n",
       "      <td>17230.7</td>\n",
       "      <td>[2294.7, 393.1, 165.4, 147.4]</td>\n",
       "      <td>0</td>\n",
       "      <td>{'occluded': False}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>[[223.2, 362.9, 219.5, 366.6, 188.7, 366.6, 18...</td>\n",
       "      <td>11394.8</td>\n",
       "      <td>[142.4, 362.9, 146.4, 98.3]</td>\n",
       "      <td>0</td>\n",
       "      <td>{'occluded': False}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>[[950.9, 75.7, 947.2, 79.4, 931.6, 79.4, 927.9...</td>\n",
       "      <td>12392.9</td>\n",
       "      <td>[924.0, 75.7, 219.5, 64.1]</td>\n",
       "      <td>0</td>\n",
       "      <td>{'occluded': False}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>[[308.0, 211.6, 304.1, 215.5, 296.4, 215.5, 28...</td>\n",
       "      <td>17849.3</td>\n",
       "      <td>[246.4, 211.6, 219.5, 98.2]</td>\n",
       "      <td>0</td>\n",
       "      <td>{'occluded': False}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>714</th>\n",
       "      <td>726</td>\n",
       "      <td>850</td>\n",
       "      <td>11</td>\n",
       "      <td>[[169.5, 302.4, 165.6, 306.1, 138.7, 306.1, 13...</td>\n",
       "      <td>29376.9</td>\n",
       "      <td>[76.9, 302.4, 396.7, 192.7]</td>\n",
       "      <td>0</td>\n",
       "      <td>{'occluded': False}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>715</th>\n",
       "      <td>727</td>\n",
       "      <td>853</td>\n",
       "      <td>11</td>\n",
       "      <td>[[365.7, 166.3, 362.0, 170.0, 288.8, 170.0, 28...</td>\n",
       "      <td>25299.0</td>\n",
       "      <td>[215.6, 166.3, 358.0, 162.5]</td>\n",
       "      <td>0</td>\n",
       "      <td>{'occluded': False}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>716</th>\n",
       "      <td>728</td>\n",
       "      <td>854</td>\n",
       "      <td>11</td>\n",
       "      <td>[[111.6, 393.1, 107.7, 396.8, 104.0, 396.8, 10...</td>\n",
       "      <td>57148.7</td>\n",
       "      <td>[0.0, 393.1, 512.0, 222.9]</td>\n",
       "      <td>0</td>\n",
       "      <td>{'occluded': False}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>717</th>\n",
       "      <td>729</td>\n",
       "      <td>855</td>\n",
       "      <td>11</td>\n",
       "      <td>[[585.2, 151.1, 581.3, 155.0, 362.0, 155.0, 35...</td>\n",
       "      <td>22138.1</td>\n",
       "      <td>[261.7, 151.1, 389.0, 128.5]</td>\n",
       "      <td>0</td>\n",
       "      <td>{'occluded': False}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>718</th>\n",
       "      <td>730</td>\n",
       "      <td>857</td>\n",
       "      <td>11</td>\n",
       "      <td>[[400.4, 136.1, 396.5, 139.8, 381.2, 139.8, 37...</td>\n",
       "      <td>26066.8</td>\n",
       "      <td>[296.4, 136.1, 358.0, 143.5]</td>\n",
       "      <td>0</td>\n",
       "      <td>{'occluded': False}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>719 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id image_id category_id  \\\n",
       "0      1        1          11   \n",
       "1      2        2          11   \n",
       "2      3        2          11   \n",
       "3      4        4          11   \n",
       "4      5        5          11   \n",
       "..   ...      ...         ...   \n",
       "714  726      850          11   \n",
       "715  727      853          11   \n",
       "716  728      854          11   \n",
       "717  729      855          11   \n",
       "718  730      857          11   \n",
       "\n",
       "                                          segmentation     area  \\\n",
       "0    [[2410.0, 638.8, 2406.3, 642.5, 2406.3, 653.8,...   3226.7   \n",
       "1    [[2329.2, 393.1, 2325.3, 396.8, 2302.4, 396.8,...  17230.7   \n",
       "2    [[223.2, 362.9, 219.5, 366.6, 188.7, 366.6, 18...  11394.8   \n",
       "3    [[950.9, 75.7, 947.2, 79.4, 931.6, 79.4, 927.9...  12392.9   \n",
       "4    [[308.0, 211.6, 304.1, 215.5, 296.4, 215.5, 28...  17849.3   \n",
       "..                                                 ...      ...   \n",
       "714  [[169.5, 302.4, 165.6, 306.1, 138.7, 306.1, 13...  29376.9   \n",
       "715  [[365.7, 166.3, 362.0, 170.0, 288.8, 170.0, 28...  25299.0   \n",
       "716  [[111.6, 393.1, 107.7, 396.8, 104.0, 396.8, 10...  57148.7   \n",
       "717  [[585.2, 151.1, 581.3, 155.0, 362.0, 155.0, 35...  22138.1   \n",
       "718  [[400.4, 136.1, 396.5, 139.8, 381.2, 139.8, 37...  26066.8   \n",
       "\n",
       "                              bbox iscrowd           attributes  \n",
       "0      [2402.4, 638.8, 57.7, 64.1]       0  {'occluded': False}  \n",
       "1    [2294.7, 393.1, 165.4, 147.4]       0  {'occluded': False}  \n",
       "2      [142.4, 362.9, 146.4, 98.3]       0  {'occluded': False}  \n",
       "3       [924.0, 75.7, 219.5, 64.1]       0  {'occluded': False}  \n",
       "4      [246.4, 211.6, 219.5, 98.2]       0  {'occluded': False}  \n",
       "..                             ...     ...                  ...  \n",
       "714    [76.9, 302.4, 396.7, 192.7]       0  {'occluded': False}  \n",
       "715   [215.6, 166.3, 358.0, 162.5]       0  {'occluded': False}  \n",
       "716     [0.0, 393.1, 512.0, 222.9]       0  {'occluded': False}  \n",
       "717   [261.7, 151.1, 389.0, 128.5]       0  {'occluded': False}  \n",
       "718   [296.4, 136.1, 358.0, 143.5]       0  {'occluded': False}  \n",
       "\n",
       "[719 rows x 8 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob, os\n",
    "import yaml\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import json\n",
    "from PIL import Image\n",
    "# from imantics import Mask\n",
    "from shapely.geometry import Polygon\n",
    "\n",
    "IMAGE_DIR = '../data/test/images/'\n",
    "# IMAGE_DIR = os.path.join(os.getcwd(), '..' ) + '/data/test/images/'\n",
    "IMAGE_PATHS = glob.glob(os.path.join(IMAGE_DIR, '*.jp*g'))\n",
    "LABEL_DIR = './input/'\n",
    "LABEL_PATHS = glob.glob(os.path.join(LABEL_DIR, '*.txt'))\n",
    "# SAVE_DIR = './labels/test_annotated/'\n",
    "\n",
    "with open(\"custom.yaml\", \"r\") as cat:\n",
    "    data = yaml.safe_load(cat)\n",
    "    category = pd.DataFrame(data['names'], columns=['name'])\n",
    "    category['id'] = category.index + 1\n",
    "    category['supercategory'] = \"\"\n",
    "    category = category[['id','name','supercategory']]\n",
    "\n",
    "\n",
    "for image_id, image_path in enumerate(IMAGE_PATHS):\n",
    "    img = Image.open(image_path)\n",
    "    if image_id == 0:\n",
    "        image = pd.DataFrame(columns=['id','width','height','file_name'])\n",
    "\n",
    "    add = dict()\n",
    "    add['id'] = image_id + 1\n",
    "    add['width'], add['height'] = img.size\n",
    "    # add['file_name']= img.filename.split(\"/\")[-1]\n",
    "    add['file_name'] = re.findall(r'^.*\\\\([^\\/]*)$',img.filename)[-1]\n",
    "    add_im = pd.DataFrame(add, index=[0])\n",
    "    image = pd.concat([image, add_im], ignore_index = True)   \n",
    "\n",
    "\n",
    "\n",
    "for txt_id, txt_path in enumerate(LABEL_PATHS):\n",
    "    if txt_id == 0:\n",
    "        df = pd.DataFrame(columns=['id','image_id','category_id','segmentation','area','bbox','iscrowd', 'attributes'])\n",
    "        full_anno = pd.DataFrame()\n",
    "    \n",
    "    with open(txt_path, 'r', encoding='utf-8-sig', errors=\"surrogateescape\") as file:\n",
    "        # if df.shape[0]==0:\n",
    "        if len(df['id']) == 0:\n",
    "            prev_defect = 0\n",
    "        else:\n",
    "            prev_defect = max(df['id'])\n",
    "        \n",
    "        for i, line in enumerate(file):\n",
    "            inner_list = [float(elt.strip()) for elt in line.split(' ')]\n",
    "            defect = dict()\n",
    "            \n",
    "            filename = re.findall(r'^.*\\\\([^\\/]*)(?:s|_mask.txt)$',txt_path)[-1] + \".jpg\"\n",
    "            # filename = re.findall(r'^.*\\\\([^\\/]*)(?:s|.txt)$',txt_path)[-1] + \".jpg\"\n",
    "            defect['id'] = prev_defect + i + 1\n",
    "            defect['image_id'] = image.loc[(image['file_name']==filename), 'id'].values[0]\n",
    "            # defect['image_id'] = txt_id + 1\n",
    "            defect['category_id'] = int(inner_list[0]) + 1\n",
    "            \n",
    "            # upscale segmentation\n",
    "            seg = np.array(inner_list[1:])\n",
    "            x_scale = image.loc[(image['id']==defect['image_id']), 'width'].values      # x width\n",
    "            y_scale = image.loc[(image['id']==defect['image_id']), 'height'].values     # y height\n",
    "            # print(x_scale, y_scale)\n",
    "            for y in range(1,len(seg),2):\n",
    "                seg[y] = round(float(seg[y] * y_scale),1)\n",
    "                seg[y-1] = round(float(seg[y-1] * x_scale),1)    \n",
    "            seg_concat = [[]]\n",
    "            seg_concat[0][:] = seg.tolist()\n",
    "            defect['segmentation'] = seg_concat\n",
    "            # defect['segmentation'] = seg.to_list()\n",
    "\n",
    "            # Find bbox\n",
    "            x_min, x_max = min(seg[::2]), max(seg[::2])\n",
    "            y_min, y_max = min(seg[1::2]), max(seg[1::2])\n",
    "            defect['bbox'] = [x_min, y_min, round(x_max-x_min,1), round(y_max-y_min,1)]\n",
    "            # Find area\n",
    "            coord = np.transpose(np.array([seg[::2],seg[1::2]])) # Polygon work with dimensions (n, 2)\n",
    "            try:\n",
    "                defect['area'] = round(Polygon(coord).area,1)\n",
    "            except:\n",
    "                print('defect id: {}, image: {}'.format(defect['id'], image.loc[(image['id']==defect['image_id']), 'file_name'].values))\n",
    "                continue\n",
    "            defect['iscrowd'] = 0\n",
    "            defect['attributes'] = {\"occluded\":False}\n",
    "\n",
    "            add_df = pd.DataFrame([defect], index=[0])\n",
    "            df = pd.concat([df, add_df], ignore_index = True)\n",
    "\n",
    "\n",
    "# Write categories, images and annotations as arrays containing individual entries as a dictionary\n",
    "# see https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_dict.html for to_dict styles\n",
    "dict_to_json = {\n",
    "    \"categories\": category.to_dict('records'),\n",
    "    \"images\": image.to_dict('records'),\n",
    "    \"annotations\": df.to_dict('records')\n",
    "    }\n",
    "\n",
    "# convert all np.integer, np.floating and np.ndarray into json recognisable int, float and lists\n",
    "class NpEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.integer):\n",
    "            return int(obj)\n",
    "        if isinstance(obj, np.floating):\n",
    "            return float(obj)\n",
    "        if isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        return json.JSONEncoder.default(self, obj)\n",
    "\n",
    "with open(\"./inferred.json\", \"w\") as outfile:\n",
    "    json.dump(dict_to_json, outfile, cls=NpEncoder)\n",
    "\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cee878fe",
   "metadata": {},
   "source": [
    "# 5) Combine COCO JSON\n",
    "\n",
    "Useful when patches and crack_longitudinal are detected using one trained model, while other defects are detected with another"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6cd4b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import json\n",
    "\n",
    "# Files to be combined\n",
    "filename = './input/inferred_withpatch.json'\n",
    "filename2 = './input/inferred_nopatch.json'\n",
    "\n",
    "# Store categories, images and annotations in separate dataframes\n",
    "with open(filename, 'r') as file:\n",
    "    data = json.load(file)\n",
    "    \n",
    "    category = findCategory(data)\n",
    "    images = findImages(data)\n",
    "    nos_image = images['id'].max()\n",
    "    df = findAnnotations(data)\n",
    "    df = df.merge(images[['id','file_name']], left_on='image_id', right_on='id')\n",
    "    df = df.rename(columns={'id_x': 'id'})\n",
    "    df = df.drop(columns=['iscrowd','attributes','id_y'])\n",
    "\n",
    "with open(filename2, 'r') as file:\n",
    "    data2 = json.load(file)\n",
    "    \n",
    "    category2 = findCategory(data2)\n",
    "    images2 = findImages(data2)\n",
    "    nos_image2 = images2['id'].max()\n",
    "    df2 = findAnnotations(data2)\n",
    "    df2 = df2.merge(images2[['id','file_name']], left_on='image_id', right_on='id')\n",
    "    df2 = df2.rename(columns={'id_x': 'id'})\n",
    "    df2 = df2.drop(columns=['iscrowd','attributes','id_y'])\n",
    "\n",
    "# Categories - Check if categories are the same\n",
    "# check length\n",
    "if len(category) != len(category2):\n",
    "    print('categories not the same. Check before proceeding')\n",
    "# check each category\n",
    "for i in range(len(category['name'])):\n",
    "    if category['name'][i] != category2['name'][i]:\n",
    "        print('category id: {} , {} in file 1 different from category id: {} , {} in file 2. Please check'.format(category['category_id'][i], category['name'][i], category2['category_id'][i], category2['name'][i]))\n",
    "# clean category for json dump\n",
    "category = category.rename(columns={'category_id': 'id'})\n",
    "category['supercategory'] = \"\"\n",
    "\n",
    "# Annotations\n",
    "# merge two annotation df\n",
    "df_new = pd.concat([df, df2], ignore_index = True)\n",
    "\n",
    "# combine and re-arrange the image info\n",
    "images_new = pd.DataFrame(columns=['id','width','height','file_name'])\n",
    "images_new['file_name'] = df_new['file_name'].unique()\n",
    "images_new = images_new.sort_values(by=['file_name'], ignore_index=True)\n",
    "images_new['id'] = images_new.index + 1\n",
    "for i in range(len(images_new['file_name'])):\n",
    "    # find out which json records the concerned image\n",
    "    if images_new['file_name'][i] in images['file_name'].tolist():\n",
    "        dim = images.loc[(images['file_name']==images_new['file_name'][i]),['width','height']]\n",
    "    elif images_new['file_name'][i] in images2['file_name'].tolist():\n",
    "        dim = images2.loc[(images2['file_name']==images_new['file_name'][i]),['width','height']]\n",
    "    else:\n",
    "        print('image not included')\n",
    "        continue\n",
    "    # paste width and height info\n",
    "    images_new.loc[i,'width'] = dim['width'].values[0]\n",
    "    images_new.loc[i,'height'] = dim['height'].values[0]\n",
    "\n",
    "\n",
    "# assign new image id and defect id in df_new\n",
    "for i in range(len(df_new['id'])):\n",
    "    df_new.loc[i, 'image_id'] = images_new.loc[(images_new['file_name']==df_new['file_name'][i]), 'id'].values\n",
    "df_new = df_new.sort_values(by=['image_id'], ignore_index=True)\n",
    "df_new['id'] = df_new.index + 1\n",
    "df_new['iscrowd'] = 0\n",
    "df_new['attributes'] = [{'occluded':False}] * len(df_new['id'])\n",
    "df_new = df_new.drop(columns=['file_name'])\n",
    "\n",
    "# Write categories, images and annotations as arrays containing individual entries as a dictionary\n",
    "# see https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_dict.html for to_dict styles\n",
    "dict_to_json = {\n",
    "    \"categories\": category.to_dict('records'),\n",
    "    \"images\": images_new.to_dict('records'),\n",
    "    \"annotations\": df_new.to_dict('records')\n",
    "    }\n",
    "\n",
    "with open(\"./combined.json\", \"w\") as outfile:\n",
    "    json.dump(dict_to_json, outfile, cls=NpEncoder)\n",
    "\n",
    "\n",
    "# df_new\n",
    "# print('image: {}. W{} * H{}'.format(images_new['file_name'][10], images_new['width'][10],images_new['height'][10]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0665978a",
   "metadata": {},
   "source": [
    "## Dataframe formats for reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "362bed7d-f222-4529-8c02-e9c8c945f103",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>file_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2464</td>\n",
       "      <td>2056</td>\n",
       "      <td>A12Area6SwallowsCrossMountnessingHuttonBrentwo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2464</td>\n",
       "      <td>2056</td>\n",
       "      <td>A12Area6SwallowsCrossMountnessingHuttonBrentwo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2464</td>\n",
       "      <td>2056</td>\n",
       "      <td>A12Area6SwallowsCrossMountnessingHuttonBrentwo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2464</td>\n",
       "      <td>2056</td>\n",
       "      <td>A12Area6SwallowsCrossMountnessingHuttonBrentwo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2464</td>\n",
       "      <td>2056</td>\n",
       "      <td>A12Area6SwallowsCrossMountnessingHuttonBrentwo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>996</td>\n",
       "      <td>2464</td>\n",
       "      <td>2056</td>\n",
       "      <td>A12Area6SwallowsCrossMountnessingHuttonBrentwo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>997</td>\n",
       "      <td>2464</td>\n",
       "      <td>2056</td>\n",
       "      <td>A12Area6SwallowsCrossMountnessingHuttonBrentwo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>998</td>\n",
       "      <td>2464</td>\n",
       "      <td>2056</td>\n",
       "      <td>A12Area6SwallowsCrossMountnessingHuttonBrentwo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>999</td>\n",
       "      <td>2464</td>\n",
       "      <td>2056</td>\n",
       "      <td>A12Area6SwallowsCrossMountnessingHuttonBrentwo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>1000</td>\n",
       "      <td>2464</td>\n",
       "      <td>2056</td>\n",
       "      <td>A12Area6SwallowsCrossMountnessingHuttonBrentwo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  width  height                                          file_name\n",
       "0       1   2464    2056  A12Area6SwallowsCrossMountnessingHuttonBrentwo...\n",
       "1       2   2464    2056  A12Area6SwallowsCrossMountnessingHuttonBrentwo...\n",
       "2       3   2464    2056  A12Area6SwallowsCrossMountnessingHuttonBrentwo...\n",
       "3       4   2464    2056  A12Area6SwallowsCrossMountnessingHuttonBrentwo...\n",
       "4       5   2464    2056  A12Area6SwallowsCrossMountnessingHuttonBrentwo...\n",
       "..    ...    ...     ...                                                ...\n",
       "995   996   2464    2056  A12Area6SwallowsCrossMountnessingHuttonBrentwo...\n",
       "996   997   2464    2056  A12Area6SwallowsCrossMountnessingHuttonBrentwo...\n",
       "997   998   2464    2056  A12Area6SwallowsCrossMountnessingHuttonBrentwo...\n",
       "998   999   2464    2056  A12Area6SwallowsCrossMountnessingHuttonBrentwo...\n",
       "999  1000   2464    2056  A12Area6SwallowsCrossMountnessingHuttonBrentwo...\n",
       "\n",
       "[1000 rows x 4 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e619ca8f-49f7-4975-8283-74db7db66ca5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category_id</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>bleeding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>raveling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>crack_transverse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>crack_longitudinal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>crack_edge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>crack_alligator</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>crack_block</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>shoving</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>rutting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>potholes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>patch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>crack_corner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>spalling</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    category_id                name\n",
       "0             1            bleeding\n",
       "1             2            raveling\n",
       "2             3    crack_transverse\n",
       "3             4  crack_longitudinal\n",
       "4             5          crack_edge\n",
       "5             6     crack_alligator\n",
       "6             7         crack_block\n",
       "7             8             shoving\n",
       "8             9             rutting\n",
       "9            10            potholes\n",
       "10           11               patch\n",
       "11           12             unknown\n",
       "12           13        crack_corner\n",
       "13           14            spalling"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "segment",
   "language": "python",
   "name": "segment"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "3646be019cb3a5824cf56c671db895a5556c48c448ddbe838a4d1bebab1d3f21"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
